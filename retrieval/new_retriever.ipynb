{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c113ad2b-2c64-454f-9220-d52c5d856e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "exp_name = '2024-10-12-18-11-59-191333 + clip_inbatch_2en_ST_F_img_proj_low_lr_200eps'\n",
    "batch_size=64\n",
    "\n",
    "out_dir = '/proj/vondrick4/naveen/coir-ret-results'\n",
    "runs_dir = '/proj/vondrick4/naveen/coir-runs'\n",
    "dataset_split = 'val'\n",
    "lasco_data_path = '/local/vondrick/naveen/coir-data/LaSCo'\n",
    "device_map = 'cuda:{}'.format(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b217330-fc3d-4013-b100-709dd36e55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_checkpoints = {\n",
    "    'CLIP-ViT-B/16': '/local/vondrick/naveen/pretrained_models/clip/clip-vit-base-patch16',\n",
    "    'CLIP-ViT-B/32': '/local/vondrick/naveen/pretrained_models/clip/clip-vit-base-patch32',\n",
    "    'CLIP-ViT-L/14': '/local/vondrick/naveen/pretrained_models/clip/clip-vit-large-patch14',\n",
    "    'CLIP-ViT-L/14@336': '/local/vondrick/naveen/pretrained_models/clip/clip-vit-large-patch14-336'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6ab876-f8bb-4d1e-b736-3fd0014b7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/proj/vondrick4/naveen/CoIR')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPVisionModelWithProjection, CLIPTextModelWithProjection\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.datasets.lasco_corpus_dataset import lasco_corpus_dataset_clip\n",
    "from src.datasets.lasco_retrieval_dataset import lasco_retrieval_dataset_clip\n",
    "from src.metrics.metrics import calculate_recall\n",
    "from src.models.clip.inbatch_2en_ST_F_img_proj import CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710790a-fe7a-4b68-a63e-3cca8af94fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc67b0-01dc-4606-80a0-4d06ce2076de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6256eba4-09a8-4a51-9d00-e3b864735e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = os.path.join(runs_dir, exp_name)\n",
    "checkpoints = sorted(list(filter(lambda x: x[:10] == 'checkpoint', os.listdir(exp_path))))\n",
    "os.makedirs(os.path.join(out_dir, exp_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed34bf5-8b63-4a54-b701-859f8e2d7392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc481e5-dde2-4327-b8b2-c0b699b098ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755fcdd-1c51-49a0-ba95-4fa42ab0a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Experiment: 2024-10-12-18-11-59-191333 + clip_inbatch_2en_ST_F_img_proj_low_lr_200eps\n",
      "Evaluating checkpoint: checkpoint-epoch=000.ckpt\n",
      "Model loaded\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Corpus: 100%|███████████████████████████████████████████████████████████████████| 623/623 [01:16<00:00,  8.20it/s]\n",
      "Retrieval Task: 100%|████████████████████████████████████████████████████████████████████| 470/470 [00:58<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint: checkpoint-epoch=001.ckpt\n",
      "Model loaded\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Corpus: 100%|█████████████████████████████████████████████████████████████████| 1897/1897 [01:15<00:00, 25.19it/s]\n",
      "Retrieval Task: 100%|██████████████████████████████████████████████████████████████████| 1431/1431 [00:59<00:00, 23.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint: checkpoint-epoch=002.ckpt\n",
      "Model loaded\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Corpus: 100%|█████████████████████████████████████████████████████████████████| 5690/5690 [01:15<00:00, 75.75it/s]\n",
      "Retrieval Task: 100%|██████████████████████████████████████████████████████████████████| 4291/4291 [01:41<00:00, 42.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint: checkpoint-epoch=003.ckpt\n",
      "Model loaded\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Corpus: 100%|█████████████████████████████████████████████████████████████████| 5690/5690 [01:16<00:00, 74.52it/s]\n",
      "Retrieval Task: 100%|██████████████████████████████████████████████████████████████████| 4291/4291 [01:42<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint: checkpoint-epoch=004.ckpt\n",
      "Model loaded\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Corpus: 100%|█████████████████████████████████████████████████████████████████| 5690/5690 [01:16<00:00, 74.58it/s]\n",
      "Retrieval Task: 100%|██████████████████████████████████████████████████████████████████| 4291/4291 [01:41<00:00, 42.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint: checkpoint-epoch=005.ckpt\n",
      "Model loaded\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Corpus:  20%|█████████████▏                                                   | 1149/5690 [00:16<00:57, 79.37it/s]"
     ]
    }
   ],
   "source": [
    "print('Evaluating Experiment: {}'.format(exp_name))\n",
    "\n",
    "exp_results = pd.DataFrame(columns=['checkpoint', 'epoch', 'Recall@1', 'Recall@5', 'Recall@10', 'Recall@50'])\n",
    "exp_results.to_csv(os.path.join(out_dir, exp_name, 'experiment_results.csv'), index=False)\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_path = os.path.join(runs_dir, exp_name, checkpoint)\n",
    "\n",
    "    print('Evaluating checkpoint: {}'.format(checkpoint))\n",
    "    model = CLIPModel.load_from_checkpoint(\n",
    "        checkpoint_path = checkpoint_path, \n",
    "        map_location=device_map\n",
    "    )\n",
    "    model.eval()\n",
    "    print('Model loaded')\n",
    "\n",
    "    clip_checkpoint_path = clip_checkpoints[model.config['model_type']]\n",
    "    print('Using device: {}'.format(device_map))\n",
    "\n",
    "    d = model.image_encoder.config.projection_dim\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.index_cpu_to_gpu(res, device, index)\n",
    "\n",
    "    corpus_dataset = lasco_corpus_dataset_clip(dataset_split, lasco_data_path, clip_checkpoint_path)\n",
    "    corpus_dataloader = DataLoader(\n",
    "        dataset=corpus_dataset,\n",
    "        collate_fn=corpus_dataset.collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=10,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    retrieval_dataset = lasco_retrieval_dataset_clip(dataset_split, lasco_data_path, clip_checkpoint_path)\n",
    "    retrieval_dataloader = DataLoader(\n",
    "        dataset=retrieval_dataset,\n",
    "        collate_fn=retrieval_dataset.collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=10,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    index_cntr = 0\n",
    "    index_id_to_image_id_map = {}\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(corpus_dataloader, desc=\"Indexing Corpus\")):\n",
    "        batch['image']['pixel_values'] = batch['image']['pixel_values'].to(device_map)\n",
    "        with torch.no_grad():\n",
    "            image_embeds = model.img_forward(batch)\n",
    "        index.add(image_embeds['image-embeds'].cpu())\n",
    "\n",
    "        batch_len = len(batch['image-key'])\n",
    "        batch_start_indx = index_cntr\n",
    "        batch_end_indx = batch_start_indx + batch_len\n",
    "\n",
    "        for key, value in zip(list(range(batch_start_indx, batch_end_indx)), batch['image-key']):\n",
    "            index_id_to_image_id_map[key] = value\n",
    "        index_cntr += batch_len\n",
    "\n",
    "    map_func = np.vectorize(lambda x: index_id_to_image_id_map[x])\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(retrieval_dataloader , desc=\"Retrieval Task\")):\n",
    "        with torch.no_grad():\n",
    "            batch['query-image']['pixel_values'] = batch['query-image']['pixel_values'].to(device_map)\n",
    "            batch['query-text']['input_ids'] = batch['query-text']['input_ids'].to(device_map)\n",
    "            batch['query-text']['attention_mask'] = batch['query-text']['attention_mask'].to(device_map)\n",
    "        \n",
    "            target_hat_embeds = model.img_txt_forward(batch)\n",
    "\n",
    "        D, I = index.search(target_hat_embeds['target-hat-embeds'].cpu(), k=50)\n",
    "        I = map_func(I)\n",
    "\n",
    "        batch_size = len(batch['query-image-id'])\n",
    "        for i in range(batch_size):\n",
    "            output.append({\n",
    "                'id': batch['id'][i],\n",
    "                'query-image-id': batch['query-image-id'][i],\n",
    "                'target-image-id': batch['target-image-id'][i],\n",
    "                'query-text-raw': batch['query-text-raw'][i],\n",
    "                'top_50_ret_cands': I[i][:].tolist(),\n",
    "                'top_50_ret_cands_cos_sims': D[i][:].tolist()\n",
    "            })\n",
    "\n",
    "    with open(os.path.join(out_dir, exp_name, 'outputs'+'-'+checkpoint+'.json'), \"w\") as json_file:\n",
    "        json.dump(output, json_file, indent=4)\n",
    "\n",
    "    metrics = []\n",
    "    ground_truths = np.array(list(map(lambda x: x['target-image-id'], output)))\n",
    "    retrieved_candidates = np.array(list(map(lambda x: x['top_50_ret_cands'], output)))\n",
    "\n",
    "    Recall_1 = 100*calculate_recall(ground_truths, retrieved_candidates, 1)\n",
    "    Recall_5 = 100*calculate_recall(ground_truths, retrieved_candidates, 5)\n",
    "    Recall_10 = 100*calculate_recall(ground_truths, retrieved_candidates, 10)\n",
    "    Recall_50 = 100*calculate_recall(ground_truths, retrieved_candidates, 50)\n",
    "    metrics.append({\"Recall@1\": Recall_1})\n",
    "    metrics.append({\"Recall@5\": Recall_5})\n",
    "    metrics.append({\"Recall@10\": Recall_10})\n",
    "    metrics.append({\"Recall@50\": Recall_50})\n",
    "\n",
    "    with open(os.path.join(out_dir, exp_name, 'metrics'+'-'+checkpoint+'.json'), \"w\") as json_file:\n",
    "        json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "    epoch = int(checkpoint[17:20])\n",
    "    new_row = pd.DataFrame([{\n",
    "        'checkpoint': checkpoint, \n",
    "        'epoch': epoch, \n",
    "        'Recall@1': Recall_1,\n",
    "        'Recall@5': Recall_5,\n",
    "        'Recall@10': Recall_10,\n",
    "        'Recall@50': Recall_50\n",
    "    }])\n",
    "    exp_results = pd.concat([exp_results, new_row], ignore_index=True)\n",
    "    exp_results.to_csv(os.path.join(out_dir, exp_name, 'experiment_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11821151-38f6-4c3a-9133-3f57d521432c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc05cb-050c-4338-938d-40ec2dbfd577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc9c6f-d34e-4b0b-8b93-c49603bca3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eee453-896e-406c-be92-6d0b026357d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd74f5c-f90f-4505-a333-95f3d6a77952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33908b7e-852e-4b1e-990e-34730d03d3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf57f93-6d43-45fc-971f-63d6157da912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea6404-145d-43f1-b9b0-ae4b47cf2a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50bc25-da55-4862-8552-6046bdc31d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975b4c5-9827-4a26-b693-e3730f4383c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed476af-6089-4e76-8714-5a226bbda505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b099e65-f85e-4022-a1ef-368d0ada41db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017577b-993c-4365-b9dc-fd4da87274b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50bdba-08fd-4e44-9350-c9fd37270fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6760c4-4e36-4ec9-97e4-3b205f4d73c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548a412-3fde-47a2-86f1-0feb7aa25906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

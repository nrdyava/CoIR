task: train       # choices: [train, test_only]
dataset_to_use: lasco       # choices: [lasco, fashioniq, cirr, circo]
checkpoint_path: "/proj/vondrick2/nd2794/pretrained_models/clip/clip-vit-base-patch32"  # Useful for training_type: start_from_checkpoint, finetune_pretrained

image_encoder_mode: train # choices: [train, freeze]
text_encoder_mode: train # choices: [train, freeze]

loss_fn:
  name: "vanilla_constrastive_cross_entrpy_loss"
  dotp_clip: 100
  temperature: 0.07
  train_temperature: False # choices: [True, False]

trainer:
  lr: 1e-5

runs_dir: '/proj/vondrick2/nd2794/CoIR/runs'


data:
  lasco:
    dir: "/proj/vondrick2/nd2794/CoIR/data/LaSCo"
    splits: ["train", "val"]
  fashioniq:
    dir: "/proj/vondrick2/nd2794/CoIR/data/FashionIQ"
    splits: ["train", "val", "test"]
  cirr:
    dir: "/proj/vondrick2/nd2794/CoIR/data/CIRR"
    splits: ["train", "val", "test1"]
  circo:
    dir: "/proj/vondrick2/nd2794/CoIR/data/CIRCO"
    splits: ["val", "test"]

model_registry:
  models_categories_available: [clip]
  models_by_category:
    clip:
      options: [CLIP-ViT-B/16, CLIP-ViT-B/32, CLIP-ViT-L/14, CLIP-ViT-L/14@336]
      checkpoints:
        CLIP-ViT-B/16: "/proj/vondrick2/nd2794/pretrained_models/clip/clip-vit-base-patch16"
        CLIP-ViT-B/32: "/proj/vondrick2/nd2794/pretrained_models/clip/clip-vit-base-patch32"
        CLIP-ViT-L/14: "/proj/vondrick2/nd2794/pretrained_models/clip/clip-vit-large-patch14"
        CLIP-ViT-L/14@336: "/proj/vondrick2/nd2794/pretrained_models/clip/clip-vit-large-patch14-336"


local_time_zone: 'US/Eastern'
TOKENIZERS_PARALLELISM: "true"    # choices: ["true", "false"]  